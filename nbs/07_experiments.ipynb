{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc65556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c7706e",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "**TODO: GIT LFS on json of logs -- migrate**\n",
    "\n",
    "> Here, we evaluate different LLM agents on our benchmark\n",
    "\n",
    "- skip_showdoc: true\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33733c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "import agents\n",
    "from claimdb.configuration import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f0e940",
   "metadata": {},
   "source": [
    "## Googleâ€™s MCP Toolbox\n",
    "\n",
    "Google makes our life easy because they built a great tool for managing\n",
    "database connections and agentic **tools**. If you want to learn more\n",
    "you can read the\n",
    "[blog](https://cloud.google.com/blog/products/ai-machine-learning/mcp-toolbox-for-databases-now-supports-model-context-protocol).\n",
    "\n",
    "Here, all we care about is setting up the database connections properly\n",
    "and defining a few tools! We will only work with the `tools.yaml` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b36c0",
   "metadata": {},
   "source": [
    "### Define SQLite connections\n",
    "\n",
    "We will first find the unique database names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0878f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/michaeltheologitis/Code/claimdb')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.project_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee96642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_names = set()\n",
    "\n",
    "with open(config.bird_dir / 'train_dev_filtered.jsonl', 'r') as f:\n",
    "    db_names = set(json.loads(line)['db_id'] for line in f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663fef1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'formula_1'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(db_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d5d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f59b4e9",
   "metadata": {},
   "source": [
    "We want to create (see [SQLite config](https://googleapis.github.io/genai-toolbox/resources/sources/sqlite/)):\n",
    "\n",
    "```yaml\n",
    "sources:\n",
    "  superhero:\n",
    "      kind: sqlite\n",
    "      database: /path/to/superhero.sqlite\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22030323",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\"sources:\"]\n",
    "for name in sorted(db_names):\n",
    "    lines.append(f\"  {name}:\")\n",
    "    lines.append(f\"    kind: sqlite\")\n",
    "    lines.append(f\"    database: {str(config.bird_databases_dir / name / (name + \".sqlite\"))}\")\n",
    "\n",
    "yaml_connections_str = \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d087ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yaml_connections_str[:550])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba733aeb",
   "metadata": {},
   "source": [
    "### Define Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce16e4e",
   "metadata": {},
   "source": [
    "Now, we want to create ([Tools](https://googleapis.github.io/genai-toolbox/resources/tools/)):\n",
    "\n",
    "```yaml\n",
    "tools:\n",
    "  superhero_execute_sql:\n",
    "    description: Executes SQL queries on the SQLite Superhero database. The queries must be SQLite-compatible.\n",
    "    kind: sqlite-execute-sql\n",
    "    source: superhero\n",
    "  ...\n",
    "```\n",
    "\n",
    "Notice here that we use Google's primitive tool (`sqlite-execute-sql`) to\n",
    "execute SQL queries on the database (this is the code that is already implemented by them). Then, we *bind* the `superhero_execute_sql` tool to the `superhero` database source we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb7271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from claimdb.preprocess_bird import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83893c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\"tools:\"]\n",
    "for name in sorted(db_names):\n",
    "    lines.append(f\"  {name}_execute_sql:\")\n",
    "    lines.append(f\"    description: Executes SQL queries on the SQLite {convert_db_name(name)} database. The queries must be SQLite-compatible.\")\n",
    "    lines.append(f\"    source: {name}\")\n",
    "    lines.append(f\"    kind: sqlite-execute-sql\")\n",
    "\n",
    "yaml_tools_str = \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027b4436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tools:\n",
      "  address_execute_sql:\n",
      "    description: Executes SQL queries on the SQLite Address database. The queries must be SQLite-compatible.\n",
      "    source: address\n",
      "    kind: sqlite-execute-sql\n",
      "  airline_execute_sql:\n",
      "    description: Executes SQL queries on the SQLite Airline database. The queries must be SQLite-compatible.\n",
      "    source: airline\n",
      "    kind: sqlite-execute-sql\n",
      "  app_store_execute_sql:\n",
      "    description: Executes SQL queries on the SQLite App Store database. The queries must be SQLite-compatible.\n",
      "    source: app_store\n",
      "    kind: sqlite-execute-sql\n",
      "  authors_execute_sql:\n",
      "    description: Executes SQL queries on the SQLite Authors database. The queries must be SQLite-compatible.\n",
      "    source: authors\n",
      "    kind: sqlite-execute-sql\n",
      "  beer_factory_execute_sql:\n",
      "    description: Executes SQL queries on the SQLite Beer Factory database. The queries must be SQLite-compatible.\n",
      "    source: beer_factory\n",
      "    kind: sqlite-execute-sql\n",
      "  bike_share_1_execute_sql:\n",
      "    description: Executes SQL queries o\n"
     ]
    }
   ],
   "source": [
    "print(yaml_tools_str[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f455c",
   "metadata": {},
   "source": [
    "### Create the YAML tools file\n",
    "\n",
    "**Finally, combine the two strings:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d56f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "yml_str = yaml_connections_str + \"\\n\" + yaml_tools_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1d06f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.project_root / \"tools.yaml\", \"w\") as f:\n",
    "    f.write(yml_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe234e8",
   "metadata": {},
   "source": [
    "Now you can run \n",
    "\n",
    "```bash \n",
    "toolbox --ui\n",
    "```\n",
    "\n",
    "and check that all is ok!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e28d802",
   "metadata": {},
   "source": [
    "### Test tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793a88d8",
   "metadata": {},
   "source": [
    "**We need to open a connection to the toolbox server first (client)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82579817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox_core import ToolboxSyncClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e6ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ToolboxSyncClient(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809bac2b",
   "metadata": {},
   "source": [
    "Now we can start loading the registered tools of `tools.yaml` and use them to query the databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf001adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_id = \"california_schools\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "california_tool = client.load_tool(f\"{db_id}_execute_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tables_query = \"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d89cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "california_tool(list_tables_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb819bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_id = \"financial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fce8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_id = \"financial\"\n",
    "\n",
    "tool = client.load_tool(f\"{db_id}_execute_sql\")\n",
    "\n",
    "tool(list_tables_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306c0e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_id = \"mental_health_survey\"\n",
    "\n",
    "tool = client.load_tool(f\"{db_id}_execute_sql\")\n",
    "\n",
    "tool(list_tables_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9e182",
   "metadata": {},
   "source": [
    "**Close the connection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb07fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be87761",
   "metadata": {},
   "source": [
    "## Prompts, I/O, Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8b6be0",
   "metadata": {},
   "source": [
    "**OpenAI's agents handle structured outputs well with the Pydantic types**. They give the descriptions correctly. that is why in the prompts you will not see me explaining specific output types more. These comments are in the pydantic (`BaseModel` as `description`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04205a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from toolbox_core import ToolboxSyncClient\n",
    "from claimdb.configuration import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9c7ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from agents import Runner, Agent, function_tool\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac6b51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from claimdb.transformation import claim_collection_json_to_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08449fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object>\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "toolbox_client = ToolboxSyncClient(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736a0241",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "API request failed with status 403 (Forbidden). Server response: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m db_id = \u001b[33m\"\u001b[39m\u001b[33mcalifornia_schools\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m california_tool = \u001b[43mtoolbox_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdb_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_execute_sql\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/journ/lib/python3.14/site-packages/toolbox_core/sync_client.py:111\u001b[39m, in \u001b[36mToolboxSyncClient.load_tool\u001b[39m\u001b[34m(self, name, auth_token_getters, bound_params)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__loop \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__thread:\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mBackground loop or thread cannot be None.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m async_tool = \u001b[43mrun_coroutine_threadsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoro\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__loop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ToolboxSyncTool(async_tool, \u001b[38;5;28mself\u001b[39m.__loop, \u001b[38;5;28mself\u001b[39m.__thread)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/journ/lib/python3.14/concurrent/futures/_base.py:450\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    452\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/journ/lib/python3.14/concurrent/futures/_base.py:395\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    397\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    398\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/journ/lib/python3.14/site-packages/toolbox_core/client.py:204\u001b[39m, in \u001b[36mToolboxClient.load_tool\u001b[39m\u001b[34m(self, name, auth_token_getters, bound_params)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# Resolve client headers\u001b[39;00m\n\u001b[32m    199\u001b[39m resolved_headers = {\n\u001b[32m    200\u001b[39m     name: \u001b[38;5;28;01mawait\u001b[39;00m resolve_value(val)\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__client_headers.items()\n\u001b[32m    202\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m manifest = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__transport.tool_get(name, resolved_headers)\n\u001b[32m    206\u001b[39m \u001b[38;5;66;03m# parse the provided definition to a tool\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m manifest.tools:\n\u001b[32m    208\u001b[39m     \u001b[38;5;66;03m# TODO: Better exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/journ/lib/python3.14/site-packages/toolbox_core/toolbox_transport.py:60\u001b[39m, in \u001b[36mToolboxTransport.tool_get\u001b[39m\u001b[34m(self, tool_name, headers)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtool_get\u001b[39m(\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m, tool_name: \u001b[38;5;28mstr\u001b[39m, headers: Optional[Mapping[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     58\u001b[39m ) -> ManifestSchema:\n\u001b[32m     59\u001b[39m     url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.__base_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/api/tool/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtool_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_manifest(url, headers)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/journ/lib/python3.14/site-packages/toolbox_core/toolbox_transport.py:50\u001b[39m, in \u001b[36mToolboxTransport.__get_manifest\u001b[39m\u001b[34m(self, url, headers)\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response.ok:\n\u001b[32m     49\u001b[39m         error_text = \u001b[38;5;28;01mawait\u001b[39;00m response.text()\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     51\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAPI request failed with status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.reason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m). Server response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     52\u001b[39m         )\n\u001b[32m     53\u001b[39m     json = \u001b[38;5;28;01mawait\u001b[39;00m response.json()\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ManifestSchema(**json)\n",
      "\u001b[31mRuntimeError\u001b[39m: API request failed with status 403 (Forbidden). Server response: "
     ]
    }
   ],
   "source": [
    "db_id = \"california_schools\"\n",
    "california_tool = toolbox_client.load_tool(f\"{db_id}_execute_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc38ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "def description(pydantic_model):\n",
    "    \"Print the field descriptions of a Pydantic model\"\n",
    "    for name, field in pydantic_model.model_fields.items():\n",
    "        print(f\"{name}: {field.description}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17285f28",
   "metadata": {},
   "source": [
    "### I/O Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0885604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "\n",
    "class ClaimVerdict(BaseModel):\n",
    "    verdict: Literal[\"ENTAILED\", \"CONTRADICTED\", \"NOT ENOUGH INFO\"] = Field(\n",
    "        ...,\n",
    "        description=\"Whether the claim is supported, contradicted, or undecidable from the database.\"\n",
    "    )\n",
    "    justification: str = Field(\n",
    "        ...,\n",
    "        description=\"Brief justification (1-2 sentences) of the verdict.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca105a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verdict: Whether the claim is supported, contradicted, or undecidable from the database.\n",
      "\n",
      "justification: Brief justification (1-2 sentences) of the verdict.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "description(ClaimVerdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7264b47",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc8e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "BASE_PROMPT = f\"\"\"\n",
    "You are a fact-checking assistant operating over structured data. You will be given a natural-language claim and optional external information. You will have access to a SQLite database and may execute arbitrary SQL queries over it using specialized tools.\n",
    "\n",
    "Your task is to determine whether the claim is \"ENTAILED\", \"CONTRADICTED\", or \"NOT ENOUGH INFO\" based on evidence you obtain from the database. The labels are defined as follows:\n",
    "\n",
    "- ENTAILED: The claim is supported by the database.\n",
    "- CONTRADICTED: The claim is refuted by the database.\n",
    "- NOT ENOUGH INFO: The database does not provide sufficient evidence to decide.\n",
    "\n",
    "Use the available tools to query the database and gather evidence before making a decision. Do not ask the user for clarification or additional information.\n",
    "\n",
    "You should always start by querying the database for the schema (tables and columns).\n",
    "\"\"\"\n",
    "\n",
    "FACT_CHECKER_PROMPT = BASE_PROMPT + f\"\"\"\n",
    "Your answer should be in JSON format, adhering to the following schema:\n",
    "{json.dumps(ClaimVerdict.model_json_schema(), indent=2)}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4237a000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "EX1 = \"\"\"\n",
    "Output Example 1:\n",
    "{\n",
    "    \"verdict\": \"ENTAILED\",\n",
    "    \"justification\": \"The database shows that the population of France is 67 million, which supports the claim.\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "EX2 = \"\"\"\n",
    "Output Example 2:\n",
    "{\n",
    "    \"verdict\": \"CONTRADICTED\",\n",
    "    \"justification\": \"The database indicates that the capital of Germany is Berlin, contradicting the claim.\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "EX3 = \"\"\"\n",
    "Output Example 3:\n",
    "{\n",
    "    \"verdict\": \"NOT ENOUGH INFO\",\n",
    "    \"justification\": \"The database does not contain any information about the population of Sacramento.\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75194875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "FACT_CHECKER_PROMPT_3SHOT = FACT_CHECKER_PROMPT + \"\\n\" + EX1 + EX2 + EX3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eba7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a fact-checking assistant operating over structured data. You will be given a natural-language claim and optional external information. You will have access to a SQLite database and may execute arbitrary SQL queries over it using specialized tools.\n",
      "\n",
      "Your task is to determine whether the claim is \"ENTAILED\", \"CONTRADICTED\", or \"NOT ENOUGH INFO\" based on evidence you obtain from the database. The labels are defined as follows:\n",
      "\n",
      "- ENTAILED: The claim is supported by the database.\n",
      "- CONTRADICTED: The claim is refuted by the database.\n",
      "- NOT ENOUGH INFO: The database does not provide sufficient evidence to decide.\n",
      "\n",
      "Use the available tools to query the database and gather evidence before making a decision. Do not ask the user for clarification or additional information.\n",
      "\n",
      "You should always start by querying the database for the schema (tables and columns).\n",
      "\n",
      "Your answer should be in JSON format, adhering to the following schema:\n",
      "{\n",
      "  \"properties\": {\n",
      "    \"verdict\": {\n",
      "      \"description\": \"Whether the claim is supported, contradicted, or undecidable from the database.\",\n",
      "      \"enum\": [\n",
      "        \"ENTAILED\",\n",
      "        \"CONTRADICTED\",\n",
      "        \"NOT ENOUGH INFO\"\n",
      "      ],\n",
      "      \"title\": \"Verdict\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"justification\": {\n",
      "      \"description\": \"Brief justification (1-2 sentences) of the verdict.\",\n",
      "      \"title\": \"Justification\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"verdict\",\n",
      "    \"justification\"\n",
      "  ],\n",
      "  \"title\": \"ClaimVerdict\",\n",
      "  \"type\": \"object\"\n",
      "}\n",
      "\n",
      "\n",
      "Output Example 1:\n",
      "{\n",
      "    \"verdict\": \"ENTAILED\",\n",
      "    \"justification\": \"The database shows that the population of France is 67 million, which supports the claim.\"\n",
      "}\n",
      "\n",
      "Output Example 2:\n",
      "{\n",
      "    \"verdict\": \"CONTRADICTED\",\n",
      "    \"justification\": \"The database indicates that the capital of Germany is Berlin, contradicting the claim.\"\n",
      "}\n",
      "\n",
      "Output Example 3:\n",
      "{\n",
      "    \"verdict\": \"NOT ENOUGH INFO\",\n",
      "    \"justification\": \"The database does not contain any information about the population of Sacramento.\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(FACT_CHECKER_PROMPT_3SHOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08928e1d",
   "metadata": {},
   "source": [
    "## OpenAI Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb42300f",
   "metadata": {},
   "source": [
    "### Single Example Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b5c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-5-nano\"\n",
    "model = \"gpt-5-mini\"\n",
    "model_dir = config.experiments_dir_pub / model\n",
    "model_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f97fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.final_benchmark_dir / 'test-public.jsonl', \"r\") as f:\n",
    "    all_claims = [json.loads(line) for line in f]\n",
    "\n",
    "claim = all_claims[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c2939",
   "metadata": {},
   "outputs": [],
   "source": [
    "claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e42cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = toolbox_client.load_tool(f\"{claim['db_name']}_execute_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022fe5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_checker_agent = Agent(\n",
    "    name=\"Fact-Checker\",\n",
    "    instructions=FACT_CHECKER_PROMPT_3SHOT,\n",
    "    model=model,\n",
    "    tools=[function_tool(tool)],\n",
    "    output_type=ClaimVerdict,\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5795bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = f\"Claim: {claim['claim']}\\nExtra Information: {claim['extra_info']}\"\n",
    "#inp = f\"Do you see what tools and metadata of tools you have?\"\n",
    "\n",
    "print(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b9162",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await Runner.run(\n",
    "    fact_checker_agent, \n",
    "    inp, \n",
    "    max_turns=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c400161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6892da",
   "metadata": {},
   "outputs": [],
   "source": [
    "claim['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddfa5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_input_list()[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699fb906",
   "metadata": {},
   "source": [
    "### Agent's RunResult to dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64033e2c",
   "metadata": {},
   "source": [
    "#### Example to understand RunResult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5011b873",
   "metadata": {},
   "source": [
    "`to_input_list()` is the complete pipeline of all things that happened in json and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8ca972",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = result.to_input_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7845006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_input_list()[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaf9824",
   "metadata": {},
   "source": [
    "Usage (see [here](https://github.com/openai/openai-agents-python/blob/f903ad0ac44e1c5c959301bd3c8721fbd4cd4e5b/examples/basic/usage_tracking.py#L41))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362bb1b2",
   "metadata": {},
   "source": [
    "#### Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0707dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def run_result_to_dict(result, ollama=False) -> dict:\n",
    "    \"\"\"Convert an Agent's RunResult to a dictionary.\"\"\"\n",
    "    info_dict = {}\n",
    "\n",
    "    if isinstance(result, Exception):\n",
    "        return {\n",
    "            'verdict': \"\",\n",
    "            'error': str(result),\n",
    "            'justification': \"\",\n",
    "            'model_name': \"\",\n",
    "            'model_settings': \"\",\n",
    "            'usage': [],\n",
    "            'to_input_list': []\n",
    "        }\n",
    "\n",
    "    # 1. Final output\n",
    "    info_dict['verdict'] = result.final_output.verdict\n",
    "    info_dict['justification'] = result.final_output.justification\n",
    "    info_dict['final_output'] = str(result.final_output)\n",
    "\n",
    "    # 2. Model Settings\n",
    "    info_dict['model_name'] = result._last_agent.model\n",
    "    if ollama: info_dict['model_name'] = info_dict['model_name'].model\n",
    "    info_dict['model_settings'] = result._last_agent.model_settings.to_json_dict()\n",
    "\n",
    "    # 3. All Requests Costs (the total is the sum)\n",
    "    usage = []\n",
    "    for request_usage in result.context_wrapper.usage.request_usage_entries:\n",
    "        cached_input_tokens = request_usage.input_tokens_details.cached_tokens\n",
    "        regular_input_tokens = request_usage.input_tokens - cached_input_tokens\n",
    "        output_tokens = request_usage.output_tokens\n",
    "\n",
    "        usage.append(\n",
    "            {\n",
    "                \"regular_input_tokens\": regular_input_tokens,\n",
    "                \"cached_input_tokens\": cached_input_tokens,\n",
    "                \"output_tokens\": output_tokens,\n",
    "            }\n",
    "        )\n",
    "    info_dict['usage'] = usage\n",
    "\n",
    "    # 4. The complete Agentic Pipeline\n",
    "    info_dict['to_input_list'] = result.to_input_list()\n",
    "\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6938f9b",
   "metadata": {},
   "source": [
    "### Run OpenAI models on All Claims\n",
    "\n",
    "Here, simply change **model** name and run this subsection of the notebook again and again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fe1959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import asyncio\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b46c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "bird_id_to_example_dict = dict()\n",
    "\n",
    "with open(config.bird_dir / 'train_dev_filtered.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        parsed = json.loads(line)\n",
    "        bird_id = parsed['bird_id']\n",
    "        bird_id_to_example_dict[bird_id] = parsed\n",
    "    \n",
    "len(bird_id_to_example_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d70da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "db_names = set(v['db_id'] for v in bird_id_to_example_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151dcb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "_tool_cache = dict()\n",
    "tool_cache = dict()\n",
    "\n",
    "for db_name in db_names:\n",
    "    tool = toolbox_client.load_tool(f\"{db_name}_execute_sql\")\n",
    "    _tool_cache[db_name] = tool\n",
    "    tool_cache[db_name] = function_tool(tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531d6747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def return_coroutines(test_claims, model):\n",
    "    cors = []\n",
    "    claim_ids = []\n",
    "\n",
    "    for claim in test_claims:\n",
    "\n",
    "        tool = tool_cache[claim['db_name']]\n",
    "\n",
    "        fact_checker_agent = Agent(\n",
    "            name=\"Fact-Checker\",\n",
    "            instructions=FACT_CHECKER_PROMPT_3SHOT,\n",
    "            model=model,\n",
    "            tools=[tool],\n",
    "            output_type=ClaimVerdict,\n",
    "        )\n",
    "\n",
    "        inp = f\"Claim: {claim['claim']}\\nExtra Information: {claim['extra_info']}\"\n",
    "\n",
    "        cors.append(Runner.run(fact_checker_agent, inp, max_turns=20))\n",
    "        \n",
    "        claim_ids.append(claim['claim_id'])\n",
    "    \n",
    "    return cors, claim_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#TODO: tool returns exception without messing up the dependancies on 07b.\n",
    "\n",
    "#model = \"gpt-5-mini\"\n",
    "#model = \"gpt-4.1-nano\"\n",
    "model = \"gpt-5-nano\"\n",
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "results_path = config.experiments_dir_pub / f\"{model}.jsonl\"\n",
    "results_path.touch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13ddfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b1532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "with open(results_path, 'r') as f:\n",
    "    already_tested = [json.loads(line)['claim_id'] for line in f]\n",
    "\n",
    "benchmark = []\n",
    "with open(config.final_benchmark_dir / 'test-public.jsonl') as f:\n",
    "    for line in f: \n",
    "        parsed_claim = json.loads(line)\n",
    "        if parsed_claim['claim_id'] in already_tested: continue\n",
    "        benchmark.append(parsed_claim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b9474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8028fa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def run_tests():\n",
    "\n",
    "    for i in range(0, len(benchmark), batch_size):\n",
    "        test_claims = benchmark[i:i+batch_size]\n",
    "\n",
    "        cors, claim_ids = return_coroutines(test_claims, model)\n",
    "\n",
    "        results = await asyncio.gather(*cors, return_exceptions=True)\n",
    "\n",
    "        for claim_id, res in zip(claim_ids, results):\n",
    "            results_dict = {'claim_id': claim_id} | run_result_to_dict(res)\n",
    "            results_path.open('a').write(json.dumps(results_dict) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bed50a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2a1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "try: from nbdev.imports import IN_NOTEBOOK\n",
    "except: IN_NOTEBOOK=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4af0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if __name__ == \"__main__\" and not IN_NOTEBOOK:\n",
    "    print(f\"#Exps Left: {len(benchmark)}\")\n",
    "    print(model)\n",
    "    asyncio.run(run_tests())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f29a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"{\\n  \\\"properties\\\": {\\n    \\\"verdict\\\": {\\n      \\\"description\\\": \\\"Whether the claim is supported, contradicted, or undecideable from the database.\\\",\\n      \\\"enum\\\": [\\n        \\\"ENTAILED\\\",\\n        \\\"CONTRADICTED\\\",\\n        \\\"NOT ENOUGH INFO\\\"\\n      ],\\n      \\\"title\\\": \\\"Verdict\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    },\\n    \\\"justification\\\": {\\n      \\\"description\\\": \\\"Brief justification (1-2 sentences) of the verdict.\\\",\\n      \\\"title\\\": \\\"Justification\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  },\\n  \\\"required\\\": [\\n    \\\"verdict\\\",\\n    \\\"justification\\\"\\n  ],\\n  \\\"title\\\": \\\"ClaimVerdict\\\",\\n  \\\"type\\\": \\\"object\\\"\\n}\\n\\n{\\\"verdict\\\": \\\"CONTRADICTED\\\", \\\"justification\\\": \\\"The average build up play speed for Heart of Midlothian is 59.6, not 72.0 as claimed.\\\"}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e3322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f8280b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163c1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a75325b",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb1db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556244c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "claimdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
