{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5810b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from claimdb.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f24af",
   "metadata": {},
   "source": [
    "# ClaimDB: A Fact Verification Benchmark over Large Structured Data\n",
    "\n",
    "> A Fact Verification Benchmark over Large Structured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16af4d1",
   "metadata": {},
   "source": [
    "[![Paper](https://img.shields.io/badge/Paper-arXiv-red.svg)](http://arxiv.org/abs/2601.14698)\n",
    "[![Website](https://img.shields.io/badge/Website-ClaimDB-blue.svg)](https://claimdb.github.io/)\n",
    "[![Dataset](https://img.shields.io/badge/ðŸ¤—%20Dataset-ClaimDB-yellow.svg)](https://huggingface.co/datasets/michaeltheologitis/claimdb)\n",
    "[![License: CC BY-SA 4.0](https://img.shields.io/badge/License-CC%20BY--SA%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-sa/4.0/)\n",
    "\n",
    "![ClaimDB Overview](paper-plots/github.png)\n",
    "\n",
    "## Overview\n",
    "\n",
    "Given a **claim** (+extra info) and a **database**, the task is to classify each claim as `ENTAILED`, `CONTRADICTED`, or `NOT ENOUGH INFO` based on the evidence of the database. There are no restrictions on how to interact with the database.\n",
    "\n",
    "Please visit our [website](https://claimdb.github.io/) for more information! From downloading the benchmark, viewing the LLM leaderboard, to exploring individual claims and seeing the ClaimDB statistics!\n",
    "\n",
    "## Project Structure\n",
    "\n",
    "    claimdb/\n",
    "    â”œâ”€â”€ claimdb/                 # Main Python package (exported from notebooks)\n",
    "    â”œâ”€â”€ nbs/                     # ClaimDB creation (0-7) + experiments and plots (7-8) notebooks \n",
    "    â”œâ”€â”€ experiments/             # Full experiment logs/traces and results\n",
    "    â”‚   â””â”€â”€ public/              # Public test results\n",
    "    â”œâ”€â”€ filter-data/             # Filtered/processed data\n",
    "    â”‚   â”œâ”€â”€ embeddings/          # Embedding files\n",
    "    â”‚   â””â”€â”€ judges/              # Judge outputs\n",
    "    â”œâ”€â”€ original-data/           # Raw source data\n",
    "    â”‚   â””â”€â”€ BIRD/                # BIRD dataset (databases not available here)\n",
    "    â”œâ”€â”€ final-benchmark/         # Final benchmark splits (train/test)\n",
    "    â”œâ”€â”€ pyproject.toml           # Project config (UV/pip)\n",
    "    â”œâ”€â”€ settings.ini             # nbdev configuration\n",
    "    â””â”€â”€ uv.lock                  # UV lockfile\n",
    "\n",
    "## Citation\n",
    "\n",
    "```bibtex\n",
    "@misc{theologitis2026claimdbfactverificationbenchmark,\n",
    "      title={ClaimDB: A Fact Verification Benchmark over Large Structured Data}, \n",
    "      author={Michael Theologitis and Preetam Prabhu Srikar Dammu and Chirag Shah and Dan Suciu},\n",
    "      year={2026},\n",
    "      eprint={2601.14698},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.CL},\n",
    "      url={https://arxiv.org/abs/2601.14698}, \n",
    "}\n",
    "```\n",
    "\n",
    "## Contact\n",
    "\n",
    "For questions or issues, please visit our [website](https://claimdb.github.io/) or open an issue in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c254b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e752ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "claimdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
